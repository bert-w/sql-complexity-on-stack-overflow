{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4f3b7e7-51f8-49eb-91fd-184489e99f18",
   "metadata": {},
   "source": [
    "# SQL Complexity\n",
    "This file calculates an SQL complexity score for all questions in the dataset using the **SQompLexity** metric, and saves these stats to a separate database table `features_sql`. Along with this complexity score, several stats are included (also coming from SQompLexity) that keep track of the different expressions and the locations of each in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a041e7-28a7-4100-92d2-f8afa49294e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import html\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "import database\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "968e0764-7fd7-4b9d-a416-287654ad49e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destination of the sqomplexity CLI tool.\n",
    "SQOMPLEXITY_COMMAND = [\"node\", \"../sqomplexity/dist/sqomplexity.js\"]\n",
    "# If true, it regenerates the SQompLexity score for all rows, even if it was set already.\n",
    "REGENERATE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e6ec334-d601-4f8b-bb2b-b6ac49e56efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two separate connections because one will be reading and one will be writing.\n",
    "db = database.Database(\"stackoverflow_mysql_queries\")\n",
    "db_updater = database.Database(\"stackoverflow_mysql_queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac4f89c0-8925-4754-ae9b-26b20787bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store(function_df, store=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Execute and save the function result if the pickle file does not exist.\n",
    "    If it does exist, the pickle file is loaded.\n",
    "    :param lambda function_df Function that returns a dataframe.\n",
    "    :param string store\n",
    "    \"\"\"\n",
    "    if store and os.path.exists(store):\n",
    "        return pd.read_pickle(store)\n",
    "    df = function_df()\n",
    "    if store:\n",
    "        df.to_pickle(store)\n",
    "    return df\n",
    "\n",
    "\n",
    "def base64encode(str) -> str:\n",
    "    try:\n",
    "        str = str.encode(\"ascii\")\n",
    "        str = base64.b64encode(str)\n",
    "        str = str.decode(\"ascii\")\n",
    "        return str\n",
    "    except:\n",
    "        # Return underscore since apparently we cannot encode it (this makes it a failing query).\n",
    "        return \"Xw==\"\n",
    "\n",
    "\n",
    "def batch_generator(generator, batch_size):\n",
    "    \"\"\"\n",
    "    Create batches for a generator.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        batch = list(itertools.islice(generator, batch_size))\n",
    "        if not batch:\n",
    "            break\n",
    "        yield batch\n",
    "\n",
    "\n",
    "def get_sql_complexity(queries, table, column_callable, id_column, total=None, batch_size=10):\n",
    "    \"\"\"\n",
    "    :param list queries: Expects tuples with (Id, Sql).\n",
    "    :param str table\n",
    "    :param callable column_callable: A callable that returns a dictionary with columns and their to be assigned values. It receives a tuple (id, json-payload-from-command).\n",
    "    \"\"\"\n",
    "\n",
    "    def dict_to_update_statement(dict) -> str:\n",
    "        \"\"\"\n",
    "        Converts a dictionary to a part of the UPDATE statement.\n",
    "        \"\"\"\n",
    "        q = [key + \" = \" + str(value) for (key, value) in dict.items()]\n",
    "        return \", \".join(q)\n",
    "\n",
    "    with tqdm(total=total) as pbar:\n",
    "        for batch in batch_generator(queries, batch_size):\n",
    "            # Call the Node CLI tool with (multiple) base64encoded queries.\n",
    "            args = SQOMPLEXITY_COMMAND.copy()\n",
    "            args.extend((base64encode(q[1]) for q in batch))\n",
    "            args.extend([\"-b\", \"-a\"])\n",
    "            keys = [i[0] for i in batch]\n",
    "            try:\n",
    "                result = subprocess.run(args, encoding=\"utf-8\", capture_output=True, text=True)\n",
    "            except FileNotFoundError:\n",
    "                # Command probably too long. Retry with single items.\n",
    "                if batch_size == 1:\n",
    "                    # Already running a single item. Throw exception.\n",
    "                    print(\"Failed to run command for Id={}\".format(\", \".join(keys)))\n",
    "                    raise\n",
    "                get_sql_complexity(\n",
    "                    batch,\n",
    "                    table,\n",
    "                    column_callable,\n",
    "                    id_column,\n",
    "                    total=len(batch),\n",
    "                    batch_size=1,\n",
    "                )\n",
    "                pbar.update(len(batch))\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                for tuple in zip(keys, json.loads(result.stdout)):\n",
    "                    db_updater.execute(\n",
    "                        {\n",
    "                            \"UPDATE\": table,\n",
    "                            \"SET\": dict_to_update_statement(column_callable(tuple)),\n",
    "                            \"WHERE\": \"{} = {}\".format(id_column, tuple[0]),\n",
    "                        }\n",
    "                    )\n",
    "                    yield tuple\n",
    "            except ValueError as err:\n",
    "                print(\"stdout: {}, stderr: {}\".format(result.stdout, result.stderr))\n",
    "                raise\n",
    "            pbar.update(len(batch))\n",
    "        pbar.close()\n",
    "\n",
    "\n",
    "def extract_sql_from_post_body(row) -> tuple:\n",
    "    body = row[1]\n",
    "    if isinstance(body, bytes):\n",
    "        body = body.decode(\"utf-8\")\n",
    "\n",
    "    # Replace `table` placeholder that is often used. It is an SQL keyword and the parser doesn't accept it.\n",
    "    body = re.sub(\" table\\b\", \" tableX \", body, flags=re.IGNORECASE)\n",
    "    body = html.unescape(body)\n",
    "\n",
    "    # Extract code blocks with SELECT, which should always be there since the database has been prefiltered.\n",
    "    queries = re.findall(r\"<pre><code>SELECT(.*?)<\\/code><\\/pre>\", body, flags=re.DOTALL)\n",
    "    if not len(queries):\n",
    "        # Wrong closing of tags, fix anyway.\n",
    "        queries = re.findall(r\"<pre><code>SELECT(.*?)<\\/pre><\\/code>\", body, flags=re.DOTALL)\n",
    "\n",
    "    if len(queries) <= 0:\n",
    "        queries = [\"_\"]\n",
    "\n",
    "    # Take the first query encountered.\n",
    "    return (row[0], \"SELECT \" + queries[0])\n",
    "\n",
    "\n",
    "def query_sql_complexity_rows(query, table, column_callable, id_column) -> list:\n",
    "    posts = db.query_generator(query)\n",
    "\n",
    "    queries = (extract_sql_from_post_body(row) for row in posts)\n",
    "\n",
    "    total = db.query(query.copy() | {\"SELECT\": \"COUNT(*)\"})[0][0]\n",
    "    scores = get_sql_complexity(queries, table, column_callable, id_column, total=total)\n",
    "\n",
    "    [s for s in scores]\n",
    "\n",
    "\n",
    "def tuple_to_features_sql_columns(prefix):\n",
    "    \"\"\"\n",
    "    Create column mappings for Questions and Answers in the `features_sql` table.\n",
    "    \"\"\"\n",
    "\n",
    "    def inner(tuple):\n",
    "        p = tuple[1]\n",
    "        columns = {\n",
    "            prefix + \"SQLComplexity\": p[\"complexity\"] if p[\"complexity\"] > -1 else \"NULL\",\n",
    "            prefix + \"SQLParseError\": 0 if p[\"complexity\"] > -1 else 1,\n",
    "        }\n",
    "        if p[\"complexity\"] > -1:\n",
    "            per_clause = p[\"stats\"][\"expressions_per_clause\"]\n",
    "            per_type = p[\"stats\"][\"expressions_per_type\"]\n",
    "            return columns | {\n",
    "                prefix + \"SQLSubqueries\": p[\"stats\"][\"subqueries\"],\n",
    "                prefix + \"SQLIsCyclic\": 1 if p[\"stats\"][\"is_cyclic\"] else 0,\n",
    "                prefix + \"SQLExprInSelect\": per_clause[\"select\"],\n",
    "                prefix + \"SQLExprInFrom\": per_clause[\"from\"],\n",
    "                prefix + \"SQLExprInJoin\": per_clause[\"join\"],\n",
    "                prefix + \"SQLExprInWhere\": per_clause[\"where\"],\n",
    "                prefix + \"SQLExprInGroupBy\": per_clause[\"group_by\"],\n",
    "                prefix + \"SQLExprInHaving\": per_clause[\"having\"],\n",
    "                prefix + \"SQLExprInOrderBy\": per_clause[\"order_by\"],\n",
    "                prefix + \"SQLExprInLimit\": per_clause[\"limit\"],\n",
    "                prefix + \"SQLExprInOffset\": per_clause[\"offset\"],\n",
    "                prefix + \"SQLExprTable\": per_type[\"table\"],\n",
    "                prefix + \"SQLExprUnary\": per_type[\"unary\"],\n",
    "                prefix + \"SQLExprBinary\": per_type[\"binary\"],\n",
    "                prefix + \"SQLExprColumn\": per_type[\"column\"],\n",
    "                prefix + \"SQLExprNumber\": per_type[\"number\"],\n",
    "                prefix + \"SQLExprAggregation\": per_type[\"aggregation_function\"],\n",
    "                prefix + \"SQLExprList\": per_type[\"list\"],\n",
    "                prefix + \"SQLExprStar\": per_type[\"star\"],\n",
    "                prefix + \"SQLExprFunction\": per_type[\"function\"],\n",
    "                prefix + \"SQLExprString\": per_type[\"string\"],\n",
    "                prefix + \"SQLExprNull\": per_type[\"null\"],\n",
    "            }\n",
    "        return columns\n",
    "\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d13c13c-1be5-41db-ae39-ea9c4aeecddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_questions = {\n",
    "    \"SELECT\": \"Id, Body\",\n",
    "    \"FROM\": \"posts INNER JOIN features_sql ON features_sql.QuestionId = posts.Id\",\n",
    "    \"WHERE\": None if REGENERATE else \"features_sql.QuestionSQLComplexity IS NULL AND features_sql.QuestionSQLParseError IS NULL\",\n",
    "}\n",
    "query_answers = {\n",
    "    \"SELECT\": \"Id, Body\",\n",
    "    \"FROM\": \"answers INNER JOIN features_sql ON features_sql.AnswerId = answers.Id\",\n",
    "    \"WHERE\": None if REGENERATE else \"features_sql.AnswerSQLComplexity IS NULL AND features_sql.AnswerSQLParseError IS NULL\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "715ed1bd-794a-47b1-b563-bd362a55f587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 94925/94925 [24:09<00:00, 65.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run for questions.\n",
    "query_sql_complexity_rows(query_questions, \"features_sql\", tuple_to_features_sql_columns(\"Question\"), \"QuestionId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a661deb3-bbc8-4e06-a158-8e90db86dc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 88039/88039 [21:01<00:00, 69.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run for answers.\n",
    "query_sql_complexity_rows(query_answers, \"features_sql\", tuple_to_features_sql_columns(\"Answer\"), \"AnswerId\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
